/**
 * @file
 * @ingroup    MPI_Wrapper
 *
 * @brief C interface wrappers for point-to-point communication
 */

#include <config.h>
#include "SCOREP_Mpi.h"
#include "scorep_mpi_communicator.h"
#include <UTILS_Error.h>
#include <SCOREP_Events.h>

/**
 * internal array of statuses
 */
static MPI_Status* scorep_mpi_status_array      = NULL;

/**
 * size of internal status array
 */
static int         scorep_mpi_status_array_size = 0;

/**
 * Get a pointer to a status array of at least 'size' statuses
 * @param  size minimal requested size
 * @return pointer to status array
 */
static MPI_Status* scorep_mpi_get_status_array(int size)
{
  if ((scorep_mpi_status_array_size == 0)
     && (size > 0))
  {
    /* -- never used: initialize -- */
    scorep_mpi_status_array = malloc(size * sizeof (MPI_Status));
    if (scorep_mpi_status_array == NULL)
    {
      UTILS_ERROR( SCOREP_ERROR_MEM_ALLOC_FAILED,
                   "We have UTILS_FATAL() to abort!" );
      abort();
    }
    scorep_mpi_status_array_size = size;
  }
  else
  if (size > scorep_mpi_status_array_size)
  {
    /* -- not enough room: expand -- */
    scorep_mpi_status_array = realloc(scorep_mpi_status_array, size * sizeof (MPI_Status));
    if (scorep_mpi_status_array == NULL)
    {
      UTILS_ERROR( SCOREP_ERROR_MEM_ALLOC_FAILED,
                   "We have UTILS_FATAL() to abort!" );
      abort();
    }
    scorep_mpi_status_array_size = size;
  }
  return scorep_mpi_status_array;
}

/**
 * @name Blocking
 * @{
 */
#pragma wrapgen multiple regex(MPI_(S|B|R)[s]?end$) skel/SCOREP_Mpi_PtpSend.w

#if HAVE(DECL_PMPI_RECV) && !defined(SCOREP_MPI_NO_P2P)
/**
 * Measurement wrapper for MPI_Recv
 * @note Manually adapted wrapper
 * @note C interface
 * @note Introduced with MPI-1
 * @ingroup p2p
 * Sequence of events:
 * @li enter region 'MPI_Recv'
 * @li MPI recv event
 * @li exit region 'MPI_Recv'
 */
int MPI_Recv( void* buf,
              int count,
              MPI_Datatype datatype,
              int source, int tag,
              MPI_Comm comm,
              MPI_Status* status )
{
  int return_val;

  if (SCOREP_MPI_IS_EVENT_GEN_ON_FOR(SCOREP_MPI_ENABLED_P2P))
  {
    int        sz;
    uint64_t start_time_stamp;
    MPI_Status mystatus;

    SCOREP_MPI_EVENT_GEN_OFF();

    SCOREP_EnterRegion(scorep_mpi_regid[SCOREP__MPI_RECV]);

    #if ! defined(SCOREP_MPI_NO_HOOKS)
      if(SCOREP_IS_MPI_HOOKS_ON)
        start_time_stamp = SCOREP_GetLastTimeStamp();
    #endif

    if (status == MPI_STATUS_IGNORE) status = &mystatus;
    return_val = PMPI_Recv(buf, count, datatype, source, tag, comm, status);

    #if ! defined(SCOREP_MPI_NO_HOOKS)
      if(SCOREP_IS_MPI_HOOKS_ON)
        SCOREP_Hooks_Post_MPI_Recv(buf, count, datatype, source, tag, comm, status, start_time_stamp, return_val);
    #endif

    if (source != MPI_PROC_NULL && return_val == MPI_SUCCESS)
    {
      PMPI_Type_size(datatype, &sz);
      PMPI_Get_count(status, datatype, &count);
      SCOREP_MpiRecv(status->MPI_SOURCE, SCOREP_MPI_COMM_HANDLE(comm),
                     status->MPI_TAG, count * sz);
    }



    SCOREP_ExitRegion(scorep_mpi_regid[SCOREP__MPI_RECV]);

    SCOREP_MPI_EVENT_GEN_ON();
  }
  else
  {
    return_val = PMPI_Recv(buf, count, datatype, source, tag, comm, status);
  }

  return return_val;
}
#endif

#pragma wrapgen single MPI_Probe skel/SCOREP_Mpi_Std.w

#pragma wrapgen multiple restrict(nMPI_Sendrecv) skel/SCOREP_Mpi_PtpSendrecv.w

/**
 * @}
 * @name Non-blocking
 * @{
 */

#pragma wrapgen multiple regex(MPI_I(s|bs|rs|ss)end$) skel/SCOREP_Mpi_PtpIsend.w

#if HAVE(DECL_PMPI_IRECV) && !defined(SCOREP_MPI_NO_P2P)
/**
 * Measurement wrapper for MPI_Irecv
 * @note Manually adapted wrapper
 * @note C interface
 * @note Introduced with MPI-1
 * @ingroup p2p
 * Triggers an enter and exit event.
 */
int MPI_Irecv(void* buf,
              int count,
              MPI_Datatype datatype,
              int source,
              int tag,
              MPI_Comm comm,
              MPI_Request* request)
{
  uint64_t start_time_stamp;
  const int event_gen_active = SCOREP_MPI_IS_EVENT_GEN_ON_FOR(SCOREP_MPI_ENABLED_P2P);
  const int xnb_active       = (scorep_mpi_enabled & SCOREP_MPI_ENABLED_XNONBLOCK);
  int       return_val;

  if (event_gen_active)
  {
    SCOREP_MPI_EVENT_GEN_OFF();

    SCOREP_EnterRegion(scorep_mpi_regid[SCOREP__MPI_IRECV]);
  }

  #if ! defined(SCOREP_MPI_NO_HOOKS)
  if(SCOREP_IS_MPI_HOOKS_ON)
  	start_time_stamp = SCOREP_GetLastTimeStamp();
  #endif

  return_val = PMPI_Irecv(buf, count, datatype, source, tag, comm, request);

  if (source != MPI_PROC_NULL && return_val == MPI_SUCCESS)
  {
    SCOREP_MpiRequestId reqid = scorep_mpi_get_request_id();
    int sz;
    PMPI_Type_size(datatype, &sz);

    if (event_gen_active && xnb_active)
      SCOREP_MpiIrecvRequest(reqid);

    scorep_mpi_request_create(*request, SCOREP_MPI_REQUEST_RECV,
                       tag, 0, count * sz, datatype, comm, reqid);
	#if !defined( SCOREP_MPI_NO_HOOKS )
    if ( SCOREP_IS_MPI_HOOKS_ON )
      SCOREP_Hooks_Post_MPI_Irecv( buf, count, datatype, source, tag, comm, request, start_time_stamp, return_val );
    #endif
  }

  if (event_gen_active)
  {
    SCOREP_ExitRegion(scorep_mpi_regid[SCOREP__MPI_IRECV]);

    SCOREP_MPI_EVENT_GEN_ON();
  }

  return return_val;
}
#endif

#pragma wrapgen single MPI_Iprobe skel/SCOREP_Mpi_Std.w

#if HAVE(DECL_PMPI_WAIT) && !defined(SCOREP_MPI_NO_P2P)
/**
 * Measurement wrapper for MPI_Wait
 * @note Manually adapted wrapper
 * @note C interface
 * @note Introduced with MPI-1
 * @ingroup p2p
 * Triggers an enter and exit event.
 */
int MPI_Wait(MPI_Request* request,
             MPI_Status* status)
{
  const int          event_gen_active = SCOREP_MPI_IS_EVENT_GEN_ON_FOR(SCOREP_MPI_ENABLED_P2P);
  int                return_val;
  MPI_Status         mystatus;
  scorep_mpi_request* orig_req;
  uint64_t   start_time_stamp;

  if (event_gen_active)
  {
    SCOREP_MPI_EVENT_GEN_OFF();

    SCOREP_EnterRegion(scorep_mpi_regid[SCOREP__MPI_WAIT]);
  }

  #if !defined( SCOREP_MPI_NO_HOOKS )
  if ( SCOREP_IS_MPI_HOOKS_ON )
    start_time_stamp = SCOREP_GetLastTimeStamp();
  #endif

  if (status == MPI_STATUS_IGNORE)
  {
    status = &mystatus;
  }

  orig_req   = scorep_mpi_request_get(*request);
  return_val = PMPI_Wait(request, status);

  #if !defined( SCOREP_MPI_NO_HOOKS )
  if ( SCOREP_IS_MPI_HOOKS_ON )
     SCOREP_Hooks_Post_MPI_Asynch_Complete_Blocking(orig_req,status,start_time_stamp);
  #endif

  scorep_mpi_check_request(orig_req, status);

  if (event_gen_active)
  {
    SCOREP_ExitRegion(scorep_mpi_regid[SCOREP__MPI_WAIT]);

    SCOREP_MPI_EVENT_GEN_ON();
  }

  return return_val;
}
#endif

#if HAVE(DECL_PMPI_WAITALL) && !defined(SCOREP_MPI_NO_P2P)
/**
 * Measurement wrapper for MPI_Waitall
 * @note Manually adapted wrapper
 * @note C interface
 * @note Introduced with MPI-1
 * @ingroup p2p
 * Triggers an enter and exit event.
 */
int MPI_Waitall(int count,
                MPI_Request* requests,
                MPI_Status* array_of_statuses)
{
  const int          event_gen_active = SCOREP_MPI_IS_EVENT_GEN_ON_FOR(SCOREP_MPI_ENABLED_P2P);
  scorep_mpi_request* orig_req;
  int                 i;
  int                return_val;
  uint64_t   start_time_stamp;

  if (event_gen_active)
  {
    SCOREP_MPI_EVENT_GEN_OFF();

    SCOREP_EnterRegion(scorep_mpi_regid[SCOREP__MPI_WAITALL]);
  }

  #if !defined( SCOREP_MPI_NO_HOOKS )
  if ( SCOREP_IS_MPI_HOOKS_ON )
    start_time_stamp = SCOREP_GetLastTimeStamp();
  #endif

  #if HAVE( MPI_STATUSES_IGNORE )
  if (array_of_statuses == MPI_STATUSES_IGNORE)
  {
    /* allocate status array for internal use */
    array_of_statuses = scorep_mpi_get_status_array(count);
  }
  #endif

  scorep_mpi_save_request_array(requests, count);

  return_val = PMPI_Waitall(count, requests, array_of_statuses);

  for (i = 0; i < count; i++)
  {
    orig_req = scorep_mpi_saved_request_get(i);

    #if !defined( SCOREP_MPI_NO_HOOKS )
    if ( SCOREP_IS_MPI_HOOKS_ON )
      SCOREP_Hooks_Post_MPI_Asynch_Complete_Blocking(orig_req,&(array_of_statuses[i]),start_time_stamp);
    #endif

    scorep_mpi_check_request(orig_req, &(array_of_statuses[i]));
  }
  if (event_gen_active)
  {
    SCOREP_ExitRegion(scorep_mpi_regid[SCOREP__MPI_WAITALL]);

    SCOREP_MPI_EVENT_GEN_ON();
  }

  return return_val;
}
#endif

#if HAVE(DECL_PMPI_WAITANY) && !defined(SCOREP_MPI_NO_P2P)
/**
 * Measurement wrapper for MPI_Waitany
 * @note Manually adapted wrapper
 * @note C interface
 * @note Introduced with MPI-1
 * @ingroup p2p
 * Triggers an enter and exit event.
 */
int MPI_Waitany(int count,
                MPI_Request* requests,
                int* index,
                MPI_Status* status)
{
  const int          event_gen_active = SCOREP_MPI_IS_EVENT_GEN_ON_FOR(SCOREP_MPI_ENABLED_P2P);
  int                return_val;
  const int          xnb_active       = (scorep_mpi_enabled & SCOREP_MPI_ENABLED_XNONBLOCK);
  scorep_mpi_request* orig_req;
  MPI_Status         mystatus;
  uint64_t   start_time_stamp;

  if (event_gen_active)
  {
    SCOREP_MPI_EVENT_GEN_OFF();

    SCOREP_EnterRegion(scorep_mpi_regid[SCOREP__MPI_WAITANY]);
  }

  #if !defined( SCOREP_MPI_NO_HOOKS )
  if ( SCOREP_IS_MPI_HOOKS_ON )
    start_time_stamp = SCOREP_GetLastTimeStamp();
  #endif

  if (status == MPI_STATUS_IGNORE)
  {
    status = &mystatus;
  }

  scorep_mpi_save_request_array(requests, count);
  return_val = PMPI_Waitany(count, requests, index, status);

  if (event_gen_active && xnb_active)
    {
      int i;

      for (i = 0; i < count; ++i) {
        orig_req = scorep_mpi_saved_request_get(i);

        if (i == *index)
        {
		  #if !defined( SCOREP_MPI_NO_HOOKS )
		  if ( SCOREP_IS_MPI_HOOKS_ON )
			SCOREP_Hooks_Post_MPI_Asynch_Complete_Blocking(orig_req,status,start_time_stamp);
          #endif
          scorep_mpi_check_request(orig_req, status);
        }
        else if (orig_req)
          SCOREP_MpiRequestTested(orig_req->id);
      }
    }
  else
    {
      orig_req   = scorep_mpi_saved_request_get(*index);
      #if !defined( SCOREP_MPI_NO_HOOKS )
      if ( SCOREP_IS_MPI_HOOKS_ON )
      	SCOREP_Hooks_Post_MPI_Asynch_Complete_Blocking(orig_req,status,start_time_stamp);
      #endif
      scorep_mpi_check_request(orig_req, status);
    }

  if (event_gen_active)
  {
    SCOREP_ExitRegion(scorep_mpi_regid[SCOREP__MPI_WAITANY]);

    SCOREP_MPI_EVENT_GEN_ON();
  }

  return return_val;
}
#endif

#if HAVE(DECL_PMPI_WAITSOME) && !defined(SCOREP_MPI_NO_P2P)
/**
 * Measurement wrapper for MPI_Waitsome
 * @note Manually adapted wrapper
 * @note C interface
 * @note Introduced with MPI-1
 * @ingroup p2p
 * Triggers an enter and exit event.
 */
int MPI_Waitsome(int incount,
                 MPI_Request *array_of_requests,
                 int *outcount,
                 int *array_of_indices,
                 MPI_Status *array_of_statuses)
{
  const int          event_gen_active = SCOREP_MPI_IS_EVENT_GEN_ON_FOR(SCOREP_MPI_ENABLED_P2P);
  int                return_val;
  const int          xnb_active       = (scorep_mpi_enabled & SCOREP_MPI_ENABLED_XNONBLOCK);
  int                i;
  scorep_mpi_request* orig_req;
  uint64_t   start_time_stamp;

  if (event_gen_active)
  {
    SCOREP_MPI_EVENT_GEN_OFF();

    SCOREP_EnterRegion(scorep_mpi_regid[SCOREP__MPI_WAITSOME]);
  }

  #if !defined( SCOREP_MPI_NO_HOOKS )
  if ( SCOREP_IS_MPI_HOOKS_ON )
    start_time_stamp = SCOREP_GetLastTimeStamp();
  #endif

  #if HAVE( MPI_STATUSES_IGNORE )
  if (array_of_statuses == MPI_STATUSES_IGNORE)
  {
    /* allocate status array for internal use */
    array_of_statuses = scorep_mpi_get_status_array(incount);
  }
  #endif

  scorep_mpi_save_request_array(array_of_requests, incount);

  return_val = PMPI_Waitsome(incount, array_of_requests, outcount,
                         array_of_indices, array_of_statuses );
  if (event_gen_active && xnb_active)
    {
      int j, tmp, cur;
      MPI_Status tmpstat;

      cur = 0;

      for (i = 0; i < incount; ++i)
        {
          orig_req = scorep_mpi_saved_request_get(i);

          if (orig_req)
            {
              for (j = cur; j < *outcount && i != array_of_indices[j]; ++j)
                ;

              if (j < *outcount)
                {
                  tmpstat               = array_of_statuses[cur];
                  #if !defined( SCOREP_MPI_NO_HOOKS )
      			  if ( SCOREP_IS_MPI_HOOKS_ON )
      				SCOREP_Hooks_Post_MPI_Asynch_Complete_Blocking(orig_req,&(array_of_statuses[cur]),start_time_stamp);
      			  #endif
                  scorep_mpi_check_request(orig_req, &(array_of_statuses[cur]));
                  array_of_statuses[j]  = tmpstat;

                  tmp                   = array_of_indices[cur];
                  array_of_indices[cur] = array_of_indices[j];
                  array_of_indices[j]   = tmp;

                  ++cur;
                }
              else
                {
                  SCOREP_MpiRequestTested(orig_req->id);
                }
            }
        }
    }
  else
    {
      for (i=0; i<*outcount; ++i)
        {
          orig_req = scorep_mpi_saved_request_get(array_of_indices[i]);
		  #if !defined( SCOREP_MPI_NO_HOOKS )
      	  if ( SCOREP_IS_MPI_HOOKS_ON )
      		SCOREP_Hooks_Post_MPI_Asynch_Complete_Blocking(orig_req,&(array_of_statuses[i]),start_time_stamp);
      	  #endif
          scorep_mpi_check_request(orig_req, &(array_of_statuses[i]));
        }
    }

  if (event_gen_active)
  {
    SCOREP_ExitRegion(scorep_mpi_regid[SCOREP__MPI_WAITSOME]);

    SCOREP_MPI_EVENT_GEN_ON();
  }

  return return_val;
}
#endif

#if HAVE(DECL_PMPI_TEST) && !defined(SCOREP_MPI_NO_P2P)
/**
 * Measurement wrapper for MPI_Test
 * @note Manually adapted wrapper
 * @note C interface
 * @note Introduced with MPI-1
 * @ingroup p2p
 * Triggers an enter and exit event.
 */
int MPI_Test(MPI_Request* request,
             int* flag,
             MPI_Status* status)
{
  const int          event_gen_active = SCOREP_MPI_IS_EVENT_GEN_ON_FOR(SCOREP_MPI_ENABLED_P2P);
  int                return_val;
  const int          xtest_active       = (scorep_mpi_enabled & SCOREP_MPI_ENABLED_XREQTEST);
  scorep_mpi_request* orig_req;
  MPI_Status         mystatus;
  uint64_t   start_time_stamp;

  if (event_gen_active)
  {
    SCOREP_MPI_EVENT_GEN_OFF();

    SCOREP_EnterRegion(scorep_mpi_regid[SCOREP__MPI_TEST]);
  }

  #if !defined( SCOREP_MPI_NO_HOOKS )
  if ( SCOREP_IS_MPI_HOOKS_ON )
    start_time_stamp = SCOREP_GetLastTimeStamp();
  #endif

  if (status == MPI_STATUS_IGNORE)
  {
    status = &mystatus;
  }
  orig_req   = scorep_mpi_request_get(*request);
  return_val = PMPI_Test(request, flag, status);
  if (*flag)
    {
   	  #if !defined( SCOREP_MPI_NO_HOOKS )
      if ( SCOREP_IS_MPI_HOOKS_ON )
        SCOREP_Hooks_Post_MPI_Asynch_Complete(orig_req,status,start_time_stamp);
      #endif
      scorep_mpi_check_request(orig_req, status);
    }
  else if (orig_req && event_gen_active && xtest_active)
    {
      SCOREP_MpiRequestTested(orig_req->id);
    }

  if (event_gen_active)
  {
    SCOREP_ExitRegion(scorep_mpi_regid[SCOREP__MPI_TEST]);

    SCOREP_MPI_EVENT_GEN_ON();
  }

  return return_val;
}
#endif

#if HAVE(DECL_PMPI_TESTANY) && !defined(SCOREP_MPI_NO_P2P)
/**
 * Measurement wrapper for MPI_Testany
 * @note Manually adapted wrapper
 * @note C interface
 * @note Introduced with MPI-1
 * @ingroup p2p
 * Triggers an enter and exit event.
 */
int MPI_Testany(int count,
                MPI_Request *array_of_requests,
                int *index,
                int *flag,
                MPI_Status *status)
{
  const int          event_gen_active = SCOREP_MPI_IS_EVENT_GEN_ON_FOR(SCOREP_MPI_ENABLED_P2P);
  int                return_val;
  const int          xtest_active       = (scorep_mpi_enabled & SCOREP_MPI_ENABLED_XREQTEST);
  scorep_mpi_request* orig_req;
  MPI_Status         mystatus;
  uint64_t   start_time_stamp;

  if (event_gen_active)
  {
    SCOREP_MPI_EVENT_GEN_OFF();

    SCOREP_EnterRegion(scorep_mpi_regid[SCOREP__MPI_TESTANY]);
  }

  #if !defined( SCOREP_MPI_NO_HOOKS )
  if ( SCOREP_IS_MPI_HOOKS_ON )
    start_time_stamp = SCOREP_GetLastTimeStamp();
  #endif

  if (status == MPI_STATUS_IGNORE)
  {
    status = &mystatus;
  }
  scorep_mpi_save_request_array(array_of_requests, count);
  return_val = PMPI_Testany( count, array_of_requests, index, flag, status );

  if (event_gen_active && xtest_active)
    {
      int i;

      for (i = 0; i < count; ++i) {
        orig_req = scorep_mpi_saved_request_get(i);

        if (*index == i)
        {
          #if !defined( SCOREP_MPI_NO_HOOKS )
      	  if ( SCOREP_IS_MPI_HOOKS_ON )
        	SCOREP_Hooks_Post_MPI_Asynch_Complete(orig_req,status,start_time_stamp);
          #endif
          scorep_mpi_check_request(orig_req, status);
        }
        else if (orig_req)
          SCOREP_MpiRequestTested(orig_req->id);
      }
    }
  else if (*flag && *index != MPI_UNDEFINED)
    {
      orig_req = scorep_mpi_saved_request_get(*index);
      #if !defined( SCOREP_MPI_NO_HOOKS )
      if ( SCOREP_IS_MPI_HOOKS_ON )
       	SCOREP_Hooks_Post_MPI_Asynch_Complete(orig_req,status,start_time_stamp);
      #endif
      scorep_mpi_check_request(orig_req, status);
    }
  if (event_gen_active)
  {
    SCOREP_ExitRegion(scorep_mpi_regid[SCOREP__MPI_TESTANY]);

    SCOREP_MPI_EVENT_GEN_ON();
  }

  return return_val;
}
#endif

#if HAVE(DECL_PMPI_TESTALL) && !defined(SCOREP_MPI_NO_P2P)
/**
 * Measurement wrapper for MPI_Testall
 * @note Manually adapted wrapper
 * @note C interface
 * @note Introduced with MPI-1
 * @ingroup p2p
 * Triggers an enter and exit event.
 */
int MPI_Testall(int count,
                MPI_Request *array_of_requests,
                int *flag,
                MPI_Status *array_of_statuses)
{
  const int          event_gen_active = SCOREP_MPI_IS_EVENT_GEN_ON_FOR(SCOREP_MPI_ENABLED_P2P);
  int                return_val;
  const int          xtest_active       = (scorep_mpi_enabled & SCOREP_MPI_ENABLED_XREQTEST);
  int                i;
  scorep_mpi_request* orig_req;
  uint64_t   start_time_stamp;

  if (event_gen_active)
  {
    SCOREP_MPI_EVENT_GEN_OFF();

    SCOREP_EnterRegion(scorep_mpi_regid[SCOREP__MPI_TESTALL]);
  }

  #if !defined( SCOREP_MPI_NO_HOOKS )
  if ( SCOREP_IS_MPI_HOOKS_ON )
    start_time_stamp = SCOREP_GetLastTimeStamp();
  #endif

  #if HAVE( MPI_STATUSES_IGNORE )
  if (array_of_statuses == MPI_STATUSES_IGNORE)
  {
    /* allocate status array for internal use */
    array_of_statuses = scorep_mpi_get_status_array(count);
  }
  #endif

  scorep_mpi_save_request_array(array_of_requests, count);

  return_val = PMPI_Testall(count, array_of_requests, flag, array_of_statuses);

  if (*flag)
    {
      for (i = 0; i < count; i++)
        {
          orig_req = scorep_mpi_saved_request_get(i);
          #if !defined( SCOREP_MPI_NO_HOOKS )
      	  if ( SCOREP_IS_MPI_HOOKS_ON )
        	SCOREP_Hooks_Post_MPI_Asynch_Complete(orig_req,&(array_of_statuses[i]),start_time_stamp);
          #endif
          scorep_mpi_check_request(orig_req, &(array_of_statuses[i]));
        }
    }
  else if (event_gen_active && xtest_active)
    {
      int i;

      for (i = 0; i < count; i++)
        {
          orig_req = scorep_mpi_saved_request_get(i);
          if (orig_req)
            SCOREP_MpiRequestTested(orig_req->id);
        }
    }
  if (event_gen_active)
  {
    SCOREP_ExitRegion(scorep_mpi_regid[SCOREP__MPI_TESTALL]);

    SCOREP_MPI_EVENT_GEN_ON();
  }

  return return_val;
}
#endif

#if HAVE(DECL_PMPI_TESTSOME) && !defined(SCOREP_MPI_NO_P2P)
/**
 * Measurement wrapper for MPI_Testsome
 * @note Manually adapted wrapper
 * @note C interface
 * @note Introduced with MPI-1
 * @ingroup p2p
 * Triggers an enter and exit event.
 */
int MPI_Testsome(int incount,
                 MPI_Request *array_of_requests,
                 int *outcount,
                 int *array_of_indices,
                 MPI_Status *array_of_statuses)
{
  const int          event_gen_active = SCOREP_MPI_IS_EVENT_GEN_ON_FOR(SCOREP_MPI_ENABLED_P2P);
  int                return_val;
  const int          xtest_active       = (scorep_mpi_enabled & SCOREP_MPI_ENABLED_XREQTEST);
  int                i;
  scorep_mpi_request* orig_req;
  uint64_t   start_time_stamp;

  if (event_gen_active)
  {
    SCOREP_MPI_EVENT_GEN_OFF();

    SCOREP_EnterRegion(scorep_mpi_regid[SCOREP__MPI_TESTSOME]);
  }

  #if !defined( SCOREP_MPI_NO_HOOKS )
  if ( SCOREP_IS_MPI_HOOKS_ON )
    start_time_stamp = SCOREP_GetLastTimeStamp();
  #endif

  #if HAVE( MPI_STATUSES_IGNORE )
  if (array_of_statuses == MPI_STATUSES_IGNORE)
  {
    /* allocate status array for internal use */
    array_of_statuses = scorep_mpi_get_status_array(incount);
  }
  #endif

  scorep_mpi_save_request_array(array_of_requests, incount);
  return_val = PMPI_Testsome( incount, array_of_requests, outcount,
                          array_of_indices, array_of_statuses );

  if (event_gen_active && xtest_active)
    {
      int cur, j, tmp;
      MPI_Status tmpstat;

      cur = 0;

      for (i=0; i<incount; ++i)
        {
          orig_req = scorep_mpi_saved_request_get(i);

          if (orig_req)
            {
              for (j = cur; j < *outcount && i != array_of_indices[j]; ++j)
                ;

              if (j < *outcount)
                {
                  tmpstat               = array_of_statuses[cur];
                  #if !defined( SCOREP_MPI_NO_HOOKS )
      	  		  if ( SCOREP_IS_MPI_HOOKS_ON )
        			SCOREP_Hooks_Post_MPI_Asynch_Complete(orig_req,&(array_of_statuses[cur]),start_time_stamp);
          		  #endif
                  scorep_mpi_check_request(orig_req, &(array_of_statuses[cur]));
                  array_of_statuses[j]  = tmpstat;

                  tmp                   = array_of_indices[cur];
                  array_of_indices[cur] = array_of_indices[j];
                  array_of_indices[j]   = tmp;

                  ++cur;
                }
              else
                {
                  SCOREP_MpiRequestTested(orig_req->id);
                }
            }
        }
    }
  else
    {
      for (i=0; i<*outcount; ++i)
        {
          orig_req = scorep_mpi_saved_request_get(array_of_indices[i]);
		  #if !defined( SCOREP_MPI_NO_HOOKS )
      	  if ( SCOREP_IS_MPI_HOOKS_ON )
        	SCOREP_Hooks_Post_MPI_Asynch_Complete(orig_req,&(array_of_statuses[i]),start_time_stamp);
          #endif
          scorep_mpi_check_request(orig_req, &(array_of_statuses[i]));
        }
    }

  if (event_gen_active)
  {
    SCOREP_ExitRegion(scorep_mpi_regid[SCOREP__MPI_TESTSOME]);

    SCOREP_MPI_EVENT_GEN_ON();
  }

  return return_val;
}
#endif

/**
 * @}
 * @name Persitent requests
 * @{
 */

#pragma wrapgen multiple regex(MPI_(S|B|R)[s]?end_init$) skel/SCOREP_Mpi_PtpSendinit.w

#if HAVE(DECL_PMPI_RECV_INIT) && !defined(SCOREP_MPI_NO_P2P)
/**
 * Measurement wrapper for MPI_Recv_init
 * @note Manually adapted wrapper
 * @note C interface
 * @note Introduced with MPI-1
 * @ingroup p2p
 * Triggers an enter and exit event.
 */
int MPI_Recv_init(void* buf,
                  int count,
                  MPI_Datatype datatype,
                  int source,
                  int tag,
                  MPI_Comm comm,
                  MPI_Request* request)
{
  const int event_gen_active = SCOREP_MPI_IS_EVENT_GEN_ON_FOR(SCOREP_MPI_ENABLED_P2P);
  int       return_val;

  if (event_gen_active)
  {
    SCOREP_MPI_EVENT_GEN_OFF();

    SCOREP_EnterRegion(scorep_mpi_regid[SCOREP__MPI_RECV_INIT]);
  }

  return_val = PMPI_Recv_init(buf, count, datatype, source, tag, comm, request);
  if (source != MPI_PROC_NULL && return_val == MPI_SUCCESS)
  {
    int sz;
    PMPI_Type_size(datatype, &sz);
    scorep_mpi_request_create(*request, (SCOREP_MPI_REQUEST_RECV | SCOREP_MPI_REQUEST_IS_PERSISTENT),
                       tag, source, count * sz, datatype, comm,
                       scorep_mpi_get_request_id());

	#if !defined( SCOREP_MPI_NO_HOOKS )
    if ( SCOREP_IS_MPI_HOOKS_ON )
	  SCOREP_Hooks_Post_MPI_Recv_init(buf, count, datatype, source, tag, comm, request,0,return_val);
    #endif
  }

  if (event_gen_active)
  {
    SCOREP_ExitRegion(scorep_mpi_regid[SCOREP__MPI_RECV_INIT]);

    SCOREP_MPI_EVENT_GEN_ON();
  }

  return return_val;
}
#endif

#if HAVE(DECL_PMPI_START) && !defined(SCOREP_MPI_NO_P2P)
/**
 * Measurement wrapper for MPI_Start
 * @note Manually adapted wrapper
 * @note C interface
 * @note Introduced with MPI-1
 * @ingroup p2p
 * Triggers an enter and exit event.
 */
int MPI_Start(MPI_Request* request)
{
  const int          event_gen_active = SCOREP_MPI_IS_EVENT_GEN_ON_FOR(SCOREP_MPI_ENABLED_P2P);
  const int          xnb_active       = (scorep_mpi_enabled & SCOREP_MPI_ENABLED_XNONBLOCK);
  int                return_val;
  uint64_t   start_time_stamp;

  if (event_gen_active)
  {
    scorep_mpi_request* req;

    SCOREP_MPI_EVENT_GEN_OFF();

    SCOREP_EnterRegion(scorep_mpi_regid[SCOREP__MPI_START]);

	#if !defined( SCOREP_MPI_NO_HOOKS )
    if ( SCOREP_IS_MPI_HOOKS_ON )
      start_time_stamp = SCOREP_GetLastTimeStamp();
    #endif

    req = scorep_mpi_request_get(*request);
    if (req && (req->flags & SCOREP_MPI_REQUEST_IS_PERSISTENT))
      {
        req->flags |= SCOREP_MPI_REQUEST_IS_ACTIVE;
        if ((req->flags & SCOREP_MPI_REQUEST_SEND) && (req->dest != MPI_PROC_NULL))
          {
            if (xnb_active)
              SCOREP_MpiIsend(req->dest, req->comm_handle,
                              req->tag, req->bytes, req->id);
            else
              SCOREP_MpiSend(req->dest, req->comm_handle,
                             req->tag, req->bytes);
          }
        else if (req->flags & SCOREP_MPI_REQUEST_RECV && xnb_active)
          {
            SCOREP_MpiIrecvRequest(req->id);
          }
      }
  }

  return_val = PMPI_Start(request);

  #if !defined( SCOREP_MPI_NO_HOOKS )
  if ( SCOREP_IS_MPI_HOOKS_ON )
  	SCOREP_Hooks_Post_MPI_Start(request,start_time_stamp,return_val);
  #endif
  if (event_gen_active)
  {
    SCOREP_ExitRegion(scorep_mpi_regid[SCOREP__MPI_START]);

    SCOREP_MPI_EVENT_GEN_ON();
  }

  return return_val;
}
#endif

#if HAVE(DECL_PMPI_STARTALL) && !defined(SCOREP_MPI_NO_P2P)
/**
 * Measurement wrapper for MPI_Startall
 * @note Manually adapted wrapper
 * @note C interface
 * @note Introduced with MPI-1
 * @ingroup p2p
 * Triggers an enter and exit event.
 */
int MPI_Startall(int count,
                 MPI_Request *array_of_requests)
{
  const int          event_gen_active = SCOREP_MPI_IS_EVENT_GEN_ON_FOR(SCOREP_MPI_ENABLED_P2P);
  const int          xnb_active       = (scorep_mpi_enabled & SCOREP_MPI_ENABLED_XNONBLOCK);
  int                return_val, i;
  uint64_t   start_time_stamp;

  if (event_gen_active)
  {
    MPI_Request*       request;

    scorep_mpi_request* req;

    SCOREP_MPI_EVENT_GEN_OFF();

    SCOREP_EnterRegion(scorep_mpi_regid[SCOREP__MPI_STARTALL]);

	#if !defined( SCOREP_MPI_NO_HOOKS )
    if ( SCOREP_IS_MPI_HOOKS_ON )
      start_time_stamp = SCOREP_GetLastTimeStamp();
    #endif

    for (i = 0; i < count; i++)
    {
      request = &array_of_requests[i];
      req     = scorep_mpi_request_get(*request);

      if (req && (req->flags & SCOREP_MPI_REQUEST_IS_PERSISTENT))
        {
          req->flags |= SCOREP_MPI_REQUEST_IS_ACTIVE;
          if ((req->flags & SCOREP_MPI_REQUEST_SEND) && (req->dest != MPI_PROC_NULL))
            {
              SCOREP_MpiIsend(req->dest, req->comm_handle,
                              req->tag, req->bytes, req->id);
            }
          else if (req->flags & SCOREP_MPI_REQUEST_RECV && xnb_active)
            {
              SCOREP_MpiIrecvRequest(req->id);
            }
        }

    }
  }

  return_val = PMPI_Startall( count, array_of_requests );

  #if !defined( SCOREP_MPI_NO_HOOKS )
  if ( SCOREP_IS_MPI_HOOKS_ON )
  {
  	for (i = 0; i < count; i++)
  	  SCOREP_Hooks_Post_MPI_Start(&array_of_requests[i],start_time_stamp,return_val);
  }
  #endif

  if (event_gen_active)
  {
    SCOREP_ExitRegion(scorep_mpi_regid[SCOREP__MPI_STARTALL]);

    SCOREP_MPI_EVENT_GEN_ON();
  }

  return return_val;
}
#endif

#if HAVE(DECL_PMPI_REQUEST_FREE) && !defined(SCOREP_MPI_NO_P2P)
/**
 * Measurement wrapper for MPI_Request_free
 * @note Manually adapted wrapper
 * @note C interface
 * @note Introduced with MPI-1
 * @ingroup p2p
 * Triggers an enter and exit event.
 */
int MPI_Request_free( MPI_Request* request )
{
  const int          event_gen_active = SCOREP_MPI_IS_EVENT_GEN_ON_FOR(SCOREP_MPI_ENABLED_P2P);
  const int          xnb_active       = (scorep_mpi_enabled & SCOREP_MPI_ENABLED_XNONBLOCK);
  int                orig_req_null    = (*request == MPI_REQUEST_NULL);
  int                return_val;
  scorep_mpi_request* req;

  if (event_gen_active)
  {
    SCOREP_MPI_EVENT_GEN_OFF();

    SCOREP_EnterRegion(scorep_mpi_regid[SCOREP__MPI_REQUEST_FREE]);
  }

  req = scorep_mpi_request_get(*request);
  #if !defined( SCOREP_MPI_NO_HOOKS )
  if ( SCOREP_IS_MPI_HOOKS_ON )
   	  SCOREP_Hooks_Pre_MPI_Request_free(req);
  #endif
  if (req)
    {
      if (req->flags & SCOREP_MPI_REQUEST_CAN_CANCEL && event_gen_active && xnb_active)
        {
          MPI_Status status;
          int        cancelled;
          /* -- Must check if request was cancelled and write the
           *    cancel event. Not doing so will confuse the trace
           *    analysis.
           */
          return_val = PMPI_Wait(request, &status);
          PMPI_Test_cancelled(&status, &cancelled);

          if (cancelled)
            SCOREP_MpiRequestCancelled(req->id);
        }

      if ((req->flags & SCOREP_MPI_REQUEST_IS_PERSISTENT) && (req->flags & SCOREP_MPI_REQUEST_IS_ACTIVE))
      {
        /* mark active requests for deallocation */
        req->flags |= SCOREP_MPI_REQUEST_DEALLOCATE;
      }
      else
      {
        /* deallocate inactive requests -*/
        scorep_mpi_request_free(req);
      }
    }

  /* -- We had to call PMPI_Wait for cancellable requests, which already
   *    frees (non-persistent) requests itself and sets them to
   *    MPI_REQUEST_NULL.
   *    As MPI_Request_free does not really like being called with
   *    MPI_REQUEST_NULL, we have to catch this situation here and only
   *    pass MPI_REQUEST_NULL if the application explicitely wanted that
   *    for some reason.
   */
  if (*request != MPI_REQUEST_NULL || orig_req_null)
    return_val = PMPI_Request_free(request);


  if (event_gen_active)
  {
    SCOREP_ExitRegion(scorep_mpi_regid[SCOREP__MPI_REQUEST_FREE]);

    SCOREP_MPI_EVENT_GEN_ON();
  }

  return return_val;
}
#endif

#if HAVE(DECL_PMPI_CANCEL) && !defined(SCOREP_MPI_NO_P2P)
/**
 * Measurement wrapper for MPI_Cancel
 * @note Manually adapted wrapper
 * @note C interface
 * @note Introduced with MPI-1
 * @ingroup p2p
 * Triggers an enter and exit event.
 */
int MPI_Cancel( MPI_Request* request )
{
  const int event_gen_active = SCOREP_MPI_IS_EVENT_GEN_ON_FOR(SCOREP_MPI_ENABLED_P2P);
  int       return_val;
  scorep_mpi_request* req;

  if (event_gen_active)
  {
    SCOREP_MPI_EVENT_GEN_OFF();

    SCOREP_EnterRegion(scorep_mpi_regid[SCOREP__MPI_CANCEL]);
  }

  /* Mark request as cancellable and check for successful cancellation
   * on request completion or MPI_Request_free.
   * If XNONBLOCK is enabled, there will be a 'cancelled' event
   * instead of a normal completion event in the trace, which can be
   * checked for by the trace analysis.
   */

  req = scorep_mpi_request_get(*request);

  if (req)
    req->flags |= SCOREP_MPI_REQUEST_CAN_CANCEL;

  return_val = PMPI_Cancel(request);

  #if !defined( SCOREP_MPI_NO_HOOKS )
  if ( SCOREP_IS_MPI_HOOKS_ON )
   	  SCOREP_Hooks_Post_MPI_Cancel(req);
  #endif

  if (event_gen_active)
  {
    SCOREP_ExitRegion(scorep_mpi_regid[SCOREP__MPI_CANCEL]);

    SCOREP_MPI_EVENT_GEN_ON();
  }

  return return_val;
}
#endif

#pragma wrapgen single MPI_Test_cancelled skel/SCOREP_Mpi_Std.w

/**
 * @}
 * @name Auxiluary functions
 * @{
 */

#pragma wrapgen multiple regex((Buffer_attach|Buffer_detach)) skel/SCOREP_Mpi_Std.w

/**
 * @}
 */

