/** @page measurement Application Measurement
\seclabel{measurement}

If an application was instrumented with @scorep, you will get an executable, which 
you can execute like the uninstrumented application. After the application run, you
will find an experiment directory in your current working directory, which contains
all recorded data. The experiment directory has the format 
<tt>scorep-YYYYMMDD_HHMM_XXXXXXXX</tt>, where <tt>YYYYMMDD</tt> and <tt>HHMM</tt> encodes
the date followed by a series of random numbers. You may specify the name of the
experiment directory by setting the environment variable \confvar{SCOREP_EXPERIMENT_DIRECTORY}
to the desired name of the directory. If the directory already exists, the existing
directory will be renamed by appending a date like above by default. You can let
@scorep abort the measurement immediately by setting \confvar{SCOREP_OVERWRITE_EXPERIMENT_DIRECTORY}
to <tt>false</tt> if the experiment directory already exists. This has only an
effect if \confvar{SCOREP_EXPERIMENT_DIRECTORY} was set too.

In general, you can record a profile and/or a event trace. Whether a profile and/or a
trace is recorded, is specified by the environment variables 
\confvar{SCOREP_ENABLE_PROFILING} and \confvar{SCOREP_ENABLE_TRACING}. If the value of this
variables is zero or <tt>false</tt>, profiling/tracing is disabled. 
Otherwise @scorep will record a profile and/or trace. By default, profiling and tracing
are both enabled.

You may start with a profiling run, because of its lower space requirements. According
to profiling results, you may configure the trace buffer limits, filtering or selective 
tracing for recording traces.

@scorep allows to configure several parameters via environment variables. After the
measurement run you can find a <tt>scorep.cfg</tt> file in your experiment directory
which contains the configuration of the measurement run. If you had not set configuration
values explicitly, the file will contain the default values. This file is safe to be used
as input for a POSIX shell. For example if you want to reuse the same configuration from
an previous measurement run something like this:

@code
$ set -a
$ . scorep.cfg
$ set +a
@endcode

@section profiling Profiling
@seclabel{profiling}

@scorep implements a call-tree based profiling system. Every node in the call tree 
represent a recorded region. The edges of the tree represent the caller-callee 
relationship: The children of a node are those regions, that are entered/exited within 
a region. The path from the root to an arbitrary node, represents a call-path. Thus, 
every node in the tree identifies also the call-path from the root to itself. 

Together with a node, the statistics for the call-path are stored. 
By default, the runtime and the number of visits are recorded. Additionally, hardware
counters can be configured and are stored for every call-path. User defined metrics
are only stored in those nodes, where the metric was triggered.

For enabling profiling, set the environment variable \confvar{SCOREP_ENABLE_PROFILING}
to 1 or <tt>true</tt>. After the execution of your application you will then find
a file, named <tt>profile.cubex</tt> in your measurement directory, which you can display
with the @cube4 with <tt>cube-qt profile.cubex</tt>. The name of the profile can be
changed through the environment variable \confvar{SCOREP_PROFILING_BASE_NAME}. The
extension <tt>.cubex</tt> will be appended to the base name you specify in the 
environment variable \confvar{SCOREP_PROFILING_BASE_NAME}.

If you want to record the profile in TAU snapshot format instead of the @cube4 format,
set <tt>SCOREP_PROFILING_FORMAT=TAU_SNAPSHOT</tt>. Vice versa, you might set 
<tt>SCOREP_PROFILING_FORMAT=CUBE4</tt> to get a @cube4 profile.

@scorep records a call tree profile. The maximum call-path depth that is recorded 
is limited to 30, by default. This avoids
extremely large profiles for recursive calls. However, this limit can be changed with
the environment variable \confvar{SCOREP_PROFILING_MAX_CALLPATH_DEPTH}. 


@subsection parameter_profiling Parameter-Based Profiling
@seclabel{parameter_profiling}

Parameter-based profiling allows to separate the recoded statistics for a region, 
depending on the values of one or multiple parameters. In the resulting call-tree,
each occurred parameter-value will create a sub-node of the region. Every parameter has
a parameter name. Thus, if multiple parameters are used, they can be distinguished and 
split the call-tree in the order of the parameter events. In the final call-tree it
looks like every parameter-name/parameter-value pair is a separate region.

Currently, the only source for parameter events is manual instrumentation 
(see Section @secref{parameter_instrumentation}).


@subsection phase_profiling Phase Profiling
@seclabel{phase_profiling}

Phase-profiling allows, to group the execution of the application into logical phases.
@scorep records a separate call-tree for every phase in the application. A phase starts
when a region of type <tt>SCOREP_USER_REGION_TYPE_PHASE</tt> 
(see Section @secref{manual_instrumentation}) is entered. If the region is exited, 
the phase
is left. If two phases are nested, then the outer phase is left, when the inner phase is
entered. If the inner phase is exited, the outer phase is re-entered. 
Figure @figref{PhaseProfiling} shows the difference in the call-tree if the regions 
with the names phase1 and phase2 are not of type 
<tt>SCOREP_USER_REGION_TYPE_PHASE</tt> on the left side and the forest if they are of 
type <tt>SCOREP_USER_REGION_TYPE_PHASE</tt> on the right side.

@img{phase_profiling.png,PhaseProfiling,Call-tree changes when using phases. The left 
side shows the calltree if no region is of type phase. The right side shows the 
call-tree forest with phases., width=0.9\textwidth}

If the phase consists of multiple partitions, and thus can not be enclosed by a single
code region, all code-regions that form the phase must have the same region handle.
The possibility to define global region handles in C/C++ might be useful for the 
definition of phases that are have multiple partitions  
(see Section @secref{manual_instrumentation}). 


@subsection dynamic_profiling Dynamic Region Profiling
@seclabel{dynamic_profiling}

When profiling, multiple visits of a callpath are summarized. However, @scorep allows
to define regions to by of type dynamic. For dynamic
regions, each entry of the region will create a separate path. For this cause, the
@scorep profiling system creates an extra parameter, named <tt>instance</tt>. On each
visit to a dynamic region, the instance parameter for this callpath is increased 
and triggered automatically. Thus, the every visit to a dynamic region generates a 
separate subtree in the profile.

As an example, let us assume that an application contains the regions <tt>foo</tt> and
<tt>main</tt>, where <tt>main</tt> calls <tt>foo</tt> three times. A regular profile
would show two callpathes:
<ul>
  <li><tt>main</tt></li>
  <li><tt>main/foo</tt></li>
</ul>
If <tt>foo</tt> is a dynamic region, the profile would contain additional subnodes for
each visit of <tt>foo</tt>. The resulting profile would contain the following
callpathes:
<ul>
  <li><tt>main</tt></li>
  <li><tt>main/foo</tt></li>
  <li><tt>main/foo/instance=0</tt></li>
  <li><tt>main/foo/instance=1</tt></li>
  <li><tt>main/foo/instance=2</tt></li>
</ul>

In this case <tt>main/foo</tt> contains the summarized statistics for all 3 visits, while
<tt>main/foo/instance=0</tt> contains the statistics for the first visits of the callpath.

@note The enumeration of the instance is per callpath and not per dynamic region. 
      In particular, if a dynamic region foo appears in 2 callpathes, it has 2
      instance number 0, one in both callpathes. It is not a global enumeration of 
      the visits to foo but enumerates the visits of foo in a particular callpath from
      0 to N.

Currently, the only possibility to define dynamic regions is via the manual region 
instrumentation, described in Section @secref{manual_instrumentation}.


@note Using dynamic regions can easily create very large profiles. Thus, use this
feature with care. If you are only interested in some parts of the application, selective
tracing (see Section @secref{selective_tracing}) might be a memory space save alternative.


@section tracing Tracing
@seclabel{tracing}

@scorep can write events to OTF2 traces. By setting the environment variable
\confvar{SCOREP_ENABLE_TRACING}, you can control whether a trace is recorded. If the
value is <tt>0</tt> or <tt>false</tt> no trace is recorded, if the value is non-zero 
or <tt>true</tt>, a trace is recorded. If the variable is not specified, 
@scorep records traces on default.
After trace recording you will find the OTF2 anchor file, named <tt>trace.otf2</tt>
in the experiment directory, along with the trace data. 



@section filtering Filtering
@seclabel{filtering}

When automatic compiler instrumentation or automated source code instrumentation with
PDT has been used to instrument user-level source-program routines, there
are cases where measurement and associated analysis are degraded,
e.g., by frequently-executed, small and/or generally uninteresting
functions, methods and subroutines.

A measurement filtering capability is therefore supported for compiler instrumented
regions, regions instrumented with @scorep user API and regions from @opari2 
instrumentation (see Section @secref{pomp_instrumentation}). 
Because PDT instrumentation (Section @secref{tau_instrumentation}) inserts,
@scorep user API instrumentation, those regions can be filtered, too.
Regions can be filtered based on their region name (e.g., their function name)
or based on the source file, in which they are defined. 

A file that contains the filter definition can be specified via the environment
variable \confvar{SCOREP_FILTERING_FILE}. If no filter definition file is specified,
all instrumented regions are recorded. For filtered regions, the enter/exit events
are not recorded in trace and profile.

The filter definition file can contain two blocks:
<ul>
  <li> One block defines filter rules for filtering regions based on the source files
       they are defined in.
  </li>
  <li> One filter block defined rules for region names.
  </li>
</ul>

When the filter rules are applied, the source file name filter is evaluated first. If
a region is filtered because it appears in a filtered source file, it can not be included
by the function name filter. If a region was defined in a not-filtered source file,
the region name filter is evaluated. This means, events for a region are not recorded
if they are filtered by the source file filter or the region name filter. Events for
a region are recorded if the region is neither filtered by the source file filter nor
by the region name filter. If one of the both filter blocks is not specified, it is 
equivalent to an empty filter block.

Beside the two filter blocks, you may use comments in the filter definition file. 
Comments start with the character '#' and is terminated by a new line.
You may use comments also inside the filter blocks. If a region name or source file
name contains '#', you must escape it with a backslash.

@subsection source_filtering Source File Name Filter Block
@seclabel{source_filtering}

The filter block for source file names, must be enclosed by 
<tt>SCOREP_FILE_NAMES_BEGIN</tt> and <tt>SCOREP_FILE_NAMES_END</tt>. In between you
can specify an arbitrary number of include and exclude rules which are evaluated in
sequential order. At the beginning all source files are included. Source files that 
are excluded after all rules are evaluated, are filtered.

An exclude rule starts with the keyword <tt>EXCLUDE</tt> followed by
one or multiple whitespace separated source file names. 
Respectively, include rules start with <tt>INCLUDE</tt>
followed by one or multiple whitespace separated file names. For the specification of 
file names, bash-like wildcards are supported. In particular, the '*' wildcard
matches an string of arbitrary length, the '?' matches exactly one arbitrary
character, or within `[]` you may specify multiple options.

@note Unlike bash, a '*' may match a string that contains slashes. E.g, you may
      use the '*' wildcard for path prefixes.

An example source file filter block could look like this:
@code
SCOREP_FILE_NAMES_BEGIN # This is a comment
  EXCLUDE */filtering/filter*
  INCLUDE */filter_test.c
SCOREP_FILE_NAMES_END
@endcode

@note The keywords (<tt>SCOREP_FILE_NAMES_BEGIN</tt>, 
      <tt>SCOREP_FILE_NAMES_END</tt>, <tt>EXCLUDE</tt>, and <tt>INCLUDE</tt>) are 
      case-sensitive.

The filtering is based on the filenames as seen by the measurement system. 
Depending on instrumentation method and compiler the actual filename may
contain the absolute path, a relative path or no path at all. The instrumentation
tool tries to create as much absolute paths as possible. Paths are 
simplified before comparison to a rule. E.g. it removes <tt>path/../</tt>, 
<tt>/./</tt> and multiple slashes. You may lookup the actual filename in the resulting
output of the measurement.


@subsection region_filtering Region Name Filter Block
@seclabel{region_filtering}

The filter block for the region names, must be enclosed by 
<tt>SCOREP_REGION_NAMES_BEGIN</tt> and <tt>SCOREP_REGION_NAMES_END</tt>. In between you
can specify an arbitrary number of include and exclude rules which are evaluated in
sequential order. At the beginning, all regions are included. Regions that 
are excluded after all rules are evaluated, are filtered. 

@note Regions that are defined in source files that are filtered, are excluded
      due to the source file filter. They can not be included anymore by an
      include rule in the region filter block.

An exclude rule starts with the keyword <tt>EXCLUDE</tt> followed by
one or multiple whitespace separated region names. 
Respectively, include rules start with <tt>INCLUDE</tt>
followed by one or multiple whitespace separated expressions. For the specification of 
file names, bash-like wildcards are supported. In particular, the '*' wildcard
matches an string of arbitrary length, the '?' matches exactly one arbitrary
character, or within `[]` you may specify multiple options.


An example region filter block could look like this:
@code
SCOREP_REGION_NAMES_BEGIN
  EXCLUDE *
  INCLUDE bar foo
          baz
          main
SCOREP_REGION_NAMES_END
@endcode

In this example all but the functions bar, foo, baz and main are filtered.

Some instrumentation methods provide only mangled function names for Fortran
subroutines and functions, where the name is made all upper/lower case or decorated
with underscores. To keep a filter definition portable, we provide the <tt>FORTRAN</tt>
keyword, which must be specified between the <tt>INCLUDE</tt> or <tt>EXCLUDE</tt>
and the expression. It will cause @scorep to consider the effects of mangling when
evaluating the expression. A Fortran rule would look like this:
@code
  EXCLUDE FORTRAN MyFortranSub
@endcode

@note The keywords (e.g., <tt>SCOREP_REGION_NAMES_BEGIN</tt>, 
      <tt>SCOREP_REGION_NAMES_END</tt>, <tt>EXCLUDE</tt>, <tt>INCLUDE</tt>, 
      and <tt>FORTRAN</tt>) are case-sensitive.

@subsection selective_tracing Selective Tracing
@seclabel{selective_tracing}

@scorep experiments record by default all events during the whole execution run.
If tracing is enabled the event data will be collected in buffers on each process
that must be adequately sized to store events from the entire execution.

Instrumented routines which are executed frequently, while only performing a
small amount of work each time they are called, have an undesirable impact on
measurement. The measurement overhead for such routines is large in 
comparison to the execution time of the uninstrumented routine, resulting in
measurement dilation. Recording these events requires significant space and
analysis takes longer with relatively little improvement in quality.
Filtering can be employed during measurement (described in Section @secref{filtering}) to
ignore events from compiler-instrumented routines or user-instrumented routines.

Another possibility is not to record the whole application run. In many cases, 
only parts of the application are of interest for analysis (e.g. a frequently
performed calculation) while other parts are of less interest (e.g., initialization
and finalization) for performance analysis. Or the calculation itself shows 
iterative behavior, where recording of one iteration would be sufficient for
analysis. Restricting recording to one or multiple time intervals during 
measurement would reduce the required space and overhead. This approach is called 
selective tracing.

@scorep provides two possibilities for selective tracing.
<ul>
  <li> A configuration file can specify traced regions. The entry and exit of those 
       regions define an interval during which events are recorded. </li>
  <li> With user instrumentation, the recording can be manually switched on /off.
       (See Section @secref{manual_instrumentation}). 
</ul>

Switching recording on or off, can result in inconsistent traces or profiles, if not
applied with care. Especially, switching recording on/off manually via the SCOREP user
instrumentation macros <tt>SCOREP_USER_RECORDING_ON</tt> and 
<tt>SCOREP_USER_RECORDING_OFF</tt> is not recommended. Inconsistent traces may result in
errors or deadlocks during analysis, or show unusable data. The consistency is endangered
if:
<ul>
  <li> @openmp events are missing in one thread while other threads have them. 
       Furthermore, the @openmp parallel region events are required if any event 
       inside a parallel region is recorded. To prevent inconsistencies from 
       incomplete recording of @openmp events, it is not possible to switch 
       recording on/off from inside a parallel region </li>
  <li> @mpi a communication is only recorded partially, e.g. if a send is missing, but
       the corresponding receive on another process is recorded. To ensure recording
       of complete communication is the responsibility of the user. 
  <li> enter/exit events are not correctly nested. </li>
</ul>

How recording can be controlled through @scorep macros which are inserted in the
application's source code, is explained in 
Section @secref{manual_instrumentation}. Thus, this section focuses on first
possibility, where the user specify traced regions via a configuration file.
Currently, selective tracing is restricted to trace recording. In profiling
is enabled, the profile will always summarize the whole execution.

For selective tracing, you can specify one or multiple traced regions. The 
recording is enabled when a traced region is entered. If the region is exited,
recording of events is switched off again. If a traced region is called inside 
another traced region, thus, the recording is already enabled, it will not disable
recording of it exits, but recording will be switched off, if all traced regions are
exited. 

For traced regions only regions from @scorep user instrumentation can be selected.
If regions from other instrumentation methods are specified in the configuration
file for selective tracing, they are ignored.

For a traced region, the recording can be restricted to certain executions of that
region. Therefor, the enters for a traced region are counted, and a particular
execution can be specified by the number of its enter. If a traced region is called
recursively, the recording is only switched off, if the exit is reached, that 
corresponds to the enter that enabled recording.

The configuration file is a simple text file, where every line contains the name of 
exactly one region. Optionally, a 
comma-separated list of execution numbers or intervals of execution numbers can be 
specified. A configuration file could look like follows:
@code
    foo
    bar 23:25, 50, 60:62
    baz 1
@endcode
This configuration file would record all executions of foo, the executions 23, 24, 25,
50, 60, 61, and 62 of bar, and the second (numbering starts with 0) execution of baz 
are recorded.

To apply the selective tracing configuration file to a measurement run of your 
application, set the environment variable \confvar{SCOREP_SELECTIVE_CONFIG_FILE}
to the configuration file and run your instrumented application. If 
\confvar{SCOREP_SELECTIVE_CONFIG_FILE} is empty, or the given file can not be opened,
the whole application run will be recorded (no selective tracing will apply).


@section rewind Trace Buffer Rewind

Introducing a long-term event-trace recording mode, the trace
buffer rewind feature allows to discard the preceding section of the event trace at certain control points
or phase markers. The live decision whether to keep or discard a section can depend on the
presence or absence of certain behaviour patterns as well as on similarity or difference
with other sections.

Based on user regions (see @secref{manual_instrumentation}), three macros are given which control the rewind. These are:

@code
SCOREP_USER_REWIND_DEFINE( regionHandle )          // to define a local region handle based on the function SCOREP_USER_REGION_DEFINE( ... )
SCOREP_USER_REWIND_POINT( regionHandle, "name" )   // similar to SCOREP_USER_REGION_BEGIN( ... ) 
SCOREP_USER_REWIND_CHECK( regionHandle, boolean )  // similar to SCOREP_USER_REGION_END( ... ) w/ additional parameter to control the rewind (yes or no) 
@endcode

The user has to specify whether or not a rewind is requested with a boolean variable in the SCOREP_USER_REWIND_CHECK function. 
There are two different approaches what to do with the rewind region in the trace based on the boolean variable.
If the boolean variable is true,
the trace buffer will be reset to an old snapshot and after that rewind
region enter and leave events will be written into the trace buffer to mark the presence
of the trace buffer rewind. This rewind region then looks like a normal user-defined region
in the trace. If the variable is false, than no events of the rewind region are written into 
the trace, so that the trace buffer looks like the user never instrumented the code w/ rewind
regions. Trace buffer 
flushes have an impact on the rewind regions, i.e. if a flush occurs all previous stored
rewind points (which are not "checked", i.e. the flush is in between the region) will be
deleted and the SCOREP_USER_REWIND_CHECK function won't write the enter/leave events into the
trace independently from the boolean variable. Wrong nested rewind regions are handled as follows:  

@code
SCOREP_USER_REWIND_POINT( point 1, ...);
... do stuff ...
SCOREP_USER_REWIND_POINT( point 2, ...);
... do stuff ...
SCOREP_USER_REWIND_CHECK( point 1, true );
... do stuff ...
SCOREP_USER_REWIND_CHECK( point 2, true );
@endcode

The check for point 2 would corrupt the trace buffer, so point 2 would be deleted and
ignored in the second check.


@subsection mpi_groups Selection of MPI Groups
@seclabel{mpi_groups}

The Message Passing Interface (MPI) adapter of @scorep supports the tracing
of most of MPI's 300+ function calls. MPI defines a so-called 'profiling
interface' that supports the provision of wrapper libraries that can
easily interposed between the user application and the MPI library
calls.

The general @scorep filtering mechanism is not applied to MPI functions. Instead,
the user can decide whether event generation is turned on or off for a group of 
@mpi functions, at strat time of the application. These groups
are the listed sub modules of this adapter. Each module has a short
string token that identifies this group. To activate event generation
for a specific group, the user can specify a comma-separated list of
tokens in the configuration variable \confvar{SCOREP_MPI_ENABLE_GROUPS}. Additionally,
special tokens exist to ease the handling by the user. A complete list
of available tokens that can be specified in the runtime configuration
is listed below.

@latexonly
\begin{table}
@endlatexonly
<table>
<tr>
 <th>Token</th><th>Module</th>
</tr>
<tr>
 <td>ALL</td><td>Activate all available modules</td>
</tr>
<tr>
 <td>DEFAULT</td><td>Activate the configured default modules of CG, COLL, ENV, IO, P2P, RMA, TOPO, XNONBLOCK. This can
 be used to easily activate additional modules.</td>
</tr>
<tr>
 <td>CG</td><td>Communicators and groups</td>
</tr>
<tr>
 <td>COLL</td><td>Collective communication</td>
</tr>
<tr>
 <td>ENV</td><td>Environmental management</td>
</tr>
<tr>
 <td>ERR</td><td>Error handlers</td>
</tr>
<tr>
 <td>EXT</td><td>External interfaces</td>
</tr>
<tr>
 <td>IO</td><td>I/O</td>
</tr>
<tr>
 <td>MISC</td><td>Miscellaneous</td>
</tr>
<tr>
 <td>P2P</td><td>Point-to-point communication</td>
</tr>
<tr>
 <td>RMA</td><td>One-sided communication</td>
</tr>
<tr>
 <td>SPAWN</td><td>Process management interface (aka Spawn)</td>
</tr>
<tr>
 <td>TOPO</td><td>Topology communicators</td>
</tr>
<tr>
 <td>TYPE</td><td>MPI Datatypes</td>
</tr>
<tr>
 <td>XNONBLOCK</td><td>Extended non-blocking communication events</td>
</tr>
<tr>
 <td>XREQTEST</td><td>Test events for tests of uncompleted requests</td>
</tr>
</table>
@latexonly
\end{table}
@endlatexonly

@note  Event generation in this context only relates to flow and
transfer events. Tracking of communicators, groups, and other internal
data is unaffected and always turned on.

Example:
<pre>
SCOREP_MPI_ENABLE_GROUPS=ENV,P2P
</pre>

This will enable event generation for environmental management, including
<tt>MPI_Init</tt> and <tt>MPI_Finalize</tt>, as well as point-to-point
communication, but will disable it for all other functions groups.

A shorthand to get event generation for all supported function calls is
<pre>
SCOREP_MPI_ENABLE_GROUPS=ALL
</pre>

A shorthand to add a single group, e.g. \p TYPE, to the configured default is
<pre>
SCOREP_MPI_ENABLE_GROUPS=DEFAULT,TYPE
</pre>

A detailed overview of the @mpi functions associated with each group can be
found in Appendix @secref{wrapperannex}.

A somehow special role plays the <tt>XNONBLOCK</tt> flag. This flag determines what kind 
of events are generated by non-blocking peer-to-peer MPI function calls. If 
<tt>XNONBLOCK</tt> is not set, an OTF2_MPI_Send event is created at the non-blocking send 
call and an OTF2_MPI_Recv event is recorded when a non-blocking receive request has 
completed.
If <tt>XNONBLOCK</tt> is set, an OTF2_Isend event is recorded at the 
non-blocking send and an OTF2_IsendComplete event when the event was 
completed. Furthermore, on a non-blocking receive, it records an 
OTF2_IRecvRequest event. On request completion an OTF2_IRecv event is recorded.
In both cases the group <tt>P2P</tt> must be enabled. Otherwise @scorep records no 
events for peer-to-peer communication functions.

@section mpi_comm_name Recording MPI Communicator Names
@seclabel{mpi_comm_name}

The measurement system tracks also the names of MPI communicators to easily
identify them later in the analysis. This is done via the
<tt>MPI_Comm_set_name</tt> call. But there are some restrictions. First, the
name of a communicator is only recorded at the first call to <tt>MPI_Comm_set_name</tt>
for this communicator. Later calls are ignored. Also this call is only
honored when the call was made from the rank which is rank 0 in this communicator.
Other calls from other ranks are ignored. And lastly the name will also be not
recorded if the communicator has only one member.


@section perf_counters Recording Performance Metrics
@seclabel{perf_metrics}

If @scorep has been built with performance metric support it is capable of recording performance counter information.
To request the measurement of certain counters, the user is required to set individual environment variables. 
The user can leave these environment variables unset to indicate that no counters are requested.

@subsection papi_counters PAPI Hardware Performance Counters
@seclabel{papi_counters}

@scorep provides the possibility to query hardware performance counters and include these
metrics into the trace and/or profile. @scorep uses the 
@href{http://icl.cs.utk.edu/papi/,Performance Application Programming Interface} 
(PAPI) to access hardware performance counters.
Recording of PAPI performance counters is enabled by setting the environment variable \confvar{SCOREP_METRIC_PAPI} to a comma-separated list of counter names.
Counter names can be any PAPI preset names or PAPI native counter names.

Example:
<pre>
SCOREP_METRIC_PAPI=PAPI_FP_OPS,PAPI_L2_TCM
</pre>

This will record the number of floating point instructions and level 2 cache misses.
If any of the requested counters is not recognized, program execution will be aborted with an error message.
The PAPI utility programs <tt>papi_avail</tt> and <tt>papi_native_avail</tt> report information about the counters available on the current platform.

If you want to change the separator used in the list of PAPI counter names, set the environment variable \confvar{SCOREP_METRIC_PAPI_SEP} to the desired character.

@note
In addition it is possible to specify metrics that will be recorded per-process. Please use \confvar{SCOREP_METRIC_PAPI_PER_PROCESS} for that reason.

@subsection rusage_counters Resource Usage Counters
@seclabel{rusage_counters}

Besides PAPI, Resource Usage Counters can be recorded.
These metrics use the Unix system call <tt>getrusage</tt> to provide information about consumed resources and operating system events such as user/system time, received signals, and number of page faults.
The manual page of <tt>getrusage</tt> provides a list of resource usage counters.
Please note that the availability of specific counters depends on the operating system.

You can enable recording of resource usage counters by setting the environment variable \confvar{SCOREP_METRIC_RUSAGE}.
The variable should contain a comma-separated list of counter names.

Example:
<pre>
SCOREP_METRIC_RUSAGE=ru_utime,ru_stime
</pre>

This will record the consumed user time and system time.
If any of the requested counters is not recognized, program execution will be aborted with an error message.

@note Please be aware of the scope of displayed resource usage statistics.
@scorep records resource usage statistics for each individual thread, if the output while configuring your @scorep installation contains something like
<pre>
RUSAGE_THREAD support: yes
</pre>
Otherwise, the information displayed is valid for the whole process.
That means, for multi-threaded programs the information is the sum of resources used by all threads in the process.


A shorthand to record all resource usage counters is
<pre>
SCOREP_METRIC_RUSAGE=all
</pre>
However, this is not recommended as most operating systems does not support all metrics.

If you want to change the separator used in the list of resource usage metrics, set the environment variable \confvar{SCOREP_METRIC_RUSAGE_SEP} to the desired character.

Example:
<pre>
SCOREP_METRIC_RUSAGE_SEP=:
</pre>
This indicates that counter names in the list are separated by colons.

@note
In addition it is possible to specify metrics that will be recorded per-process. Please use \confvar{SCOREP_METRIC_RUSAGE_PER_PROCESS} for that reason.

@section cuda_adapter CUDA Performance Measurement
@seclabel{cuda_adapter}

If @scorep has been built with CUDA support it is capable of recording CUDA API function calls and GPU activities. The measurement is based on NVIDIA's <b>CU</b>DA <b>P</b>rofiling and <b>T</b>ool <b>I</b>nterface (CUPTI), which is an integral part of the CUDA Toolkit since version 4.1.

@scorep can wrap the NVIDIA compiler (<b><tt>scorep nvcc</tt></b>) to instrument .cu files. If @scorep has been built with the Intel compiler an additional flag has to be added for instrumentation: <tt>--compiler-bindir=<path-to-intel-compiler-command></tt>. Otherwise the program will not be instrumented, as <tt>nvcc</tt> uses the GNU compiler by default. 

Setting the environment variable \confvar{SCOREP_CUDA_ENABLE} to <b><tt>yes</tt></b> enables CUDA measurement. 
To enable a particular composition of CUDA measurement features the variable should contain a comma-separated list of the following CUDA measurement options:

@code
runtime = CUDA runtime API
driver  = CUDA driver API
kernel  = CUDA kernels
idle    = GPU compute idle time
yes/DEFAULT/1 = "runtime,kernel"
no = disable CUDA measurement (same as unset SCOREP_CUDA_ENABLE)
@endcode

@note @scorep supports CUDA monitoring since CUDA toolkit version 4.1. Make sure that the @scorep installation has configured CUDA support. The configure summary should contain the line: 
<pre>CUDA support: yes</pre>
If not, for most systems it is sufficient to specify the CUDA toolkit directory at @scorep configuration time: 
<pre> --with-libcudart=<path-to-cuda-toolkit-directory></pre>
Otherwise check the configure help output to specify the location of the CUDA toolkit and CUPTI libraries and include files: 
<pre> ./configure --help=recursive | grep -E "(cuda|cupti)"</pre>


@section online_access_measurement Online Access Interface
@seclabel{online_access_measurement}

Online Access (OA) is an interface to the measurement system of @scorep allowing online analysis capable tools to 
configure and retrieve profile measurements remotely over sockets. 

The Online Access interface implememts a client-server paradigm, where @scorep acts as a server accepting connections 
from the remote tool. During the initialization, the OA module of the @scorep creates one socket for each application 
process. The network addresses and the ports of these sockets are published at the registry service  
and could be later queried by the remote tool. The hostname and the port of the registry service should be specified 
via the \confvar{SCOREP_ONLINEACCESS_REG_HOST} and \confvar{SCOREP_ONLINEACCESS_REG_PORT} environment variables, respectively. After publishing the socket 
addresses and ports, the OA module will accept connections. Once the connection is established the OA module will suspend the 
application execution and wait for requests. The format of the requests is plain text following the syntax below: 

@code
<request>              = <configuration> | <execution> | <retrieval>
<configuration>        = BEGINREQUESTS GLOBAL <request_type> ENDREQUESTS
<request_type>         = MPI | EXECUTION_TIME | METRIC <metric_specification>
<metric_specification> = PERISCOPE <periscope_metric_code> | PAPI "<papi_counter_name>" | RUSAGE "rusage_metric_name" | OTHER "metric_name"
<execution>            = TERMINATE | RUNTOSTART | RUNTOEND
<retrieval>            = GETSUMMARYDATA 
@endcode

where 
<ul>
 <li>
    <tt>BEGINREQUESTS</tt> indicates the beginning of the request list, 
 </li>
 <li>
    <tt>ENDREQUESTS</tt> indicates the end of the request list, 
 </li>
 <li>
    <tt>GLOBAL</tt> indicates that the following measurement request is applied to all locations, 
 </li>
 <li>
    <tt>MPI</tt> requests mpi wait states analysis, 
 </li>
 <li>
    <tt>EXECUTION_TIME</tt> requests execution time, 
 </li>
  <li>
    <tt>METRIC</tt> indicates the begin of the metric request, 
 </li>
 <li>
    <tt>PERISCOPE <periscope_metric_code></tt> requests a metric by the Periscope internal code, 
 </li>
 <li>
    <tt>PAPI <papi_counter_name></tt> requests a a PAPI hardware counter metric by the counter name, 
 </li>
 <li>
    <tt>RUSAGE <rusage_counter_name></tt> requests a Resource Usage Counter metric by the counter name, 
 </li>
  <li>
    <tt>OTHER <metric_name></tt> requests a metric, to be defined in @scorep definition system, specified by the name, 
 </li>
 <li>
    <tt>TERMINATE</tt> requests termination of the application, 
 </li>
 <li>
    <tt>RUNTOSTART</tt> requests @scorep to run the beginning of the OA phase, 
 </li>
 <li>
    <tt>RUNTOEND</tt> requests @scorep to run the end of the OA phase, 
 </li>
 <li>
    <tt>GETSUMMARYDATA</tt> requests retrieval of the profile data.
 </li>
</ul>

When the <tt>GETSUMMARY</tt> request is received, the OA module will transform the call-path profile into a  flat profile and send 
the data back to the remote tool. The flat profile is sent in two parts, where the first part carries the region 
definition data and the second part carries profile measurements. Each part starts with the key word <tt>MERGED_REGION_DEFINITIONS</tt> 
or <tt>FLAT_PROFILE</tt> and followed by the number of the entries and the buffer containing the data.

*/
